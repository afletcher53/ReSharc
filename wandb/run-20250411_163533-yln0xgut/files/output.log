--- GPU Memory before Dataset load ---
Device: NVIDIA GeForce RTX 4070 Ti SUPER
  Allocated: 0.00 MB
  Reserved (Cached): 0.00 MB
  Total: 16376.00 MB
  Free: 14778.69 MB
  Used (Total - Free): 1597.31 MB
--- GPU Memory after Dataset load ---
Device: NVIDIA GeForce RTX 4070 Ti SUPER
  Allocated: 0.00 MB
  Reserved (Cached): 0.00 MB
  Total: 16376.00 MB
  Free: 14755.00 MB
  Used (Total - Free): 1621.00 MB
Qwen2ForCausalLM(
  (model): Qwen2Model(
    (embed_tokens): Embedding(151936, 896)
    (layers): ModuleList(
      (0-23): 24 x Qwen2DecoderLayer(
        (self_attn): Qwen2SdpaAttention(
          (q_proj): Linear(in_features=896, out_features=896, bias=True)
          (k_proj): Linear(in_features=896, out_features=128, bias=True)
          (v_proj): Linear(in_features=896, out_features=128, bias=True)
          (o_proj): Linear(in_features=896, out_features=896, bias=False)
          (rotary_emb): Qwen2RotaryEmbedding()
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)
          (up_proj): Linear(in_features=896, out_features=4864, bias=False)
          (down_proj): Linear(in_features=4864, out_features=896, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((896,), eps=1e-06)
    (rotary_emb): Qwen2RotaryEmbedding()
  )
  (lm_head): Linear(in_features=896, out_features=151936, bias=False)
)
trainable params: 276,480 || all params: 494,309,248 || trainable%: 0.0559
1977.240192
Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 522.84 examples/s]
Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 322.88 examples/s]
[34m[1mwandb[39m[22m: [33mWARNING[39m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
  0%|                                                                                                                                                                                                 | 0/150 [00:00<?, ?it/s]
{'loss': 1.0557, 'grad_norm': 0.5958252549171448, 'learning_rate': 0.004833333333333334, 'epoch': 0.17}
{'loss': 0.3362, 'grad_norm': 0.23183196783065796, 'learning_rate': 0.004666666666666667, 'epoch': 0.33}

 10%|██████████████████▍                                                                                                                                                                     | 15/150 [00:01<00:19,  7.07it/s]
{'loss': 0.1499, 'grad_norm': 0.2925249934196472, 'learning_rate': 0.004333333333333334, 'epoch': 0.67}
{'loss': 0.1391, 'grad_norm': 0.17748670279979706, 'learning_rate': 0.004166666666666667, 'epoch': 0.83}
 20%|████████████████████████████████████▊                                                                                                                                                   | 30/150 [00:03<00:13,  8.89it/s]
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 7/10 [00:00<00:00, 11.73it/s]
{'eval_loss': 0.11212563514709473, 'eval_runtime': 0.9174, 'eval_samples_per_second': 10.9, 'eval_steps_per_second': 10.9, 'epoch': 1.0}
{'loss': 0.11, 'grad_norm': 0.30919569730758667, 'learning_rate': 0.0038333333333333336, 'epoch': 1.17}

{'loss': 0.1674, 'grad_norm': 0.21529093384742737, 'learning_rate': 0.0036666666666666666, 'epoch': 1.33}
{'loss': 0.0771, 'grad_norm': 0.1607690453529358, 'learning_rate': 0.0034999999999999996, 'epoch': 1.5}
{'loss': 0.0828, 'grad_norm': 0.4576272666454315, 'learning_rate': 0.003333333333333333, 'epoch': 1.67}
 40%|█████████████████████████████████████████████████████████████████████████▌                                                                                                              | 60/150 [00:08<00:10,  8.59it/s]
  0%|                                                                                                                                                                                                  | 0/10 [00:00<?, ?it/s]
{'loss': 0.0593, 'grad_norm': 0.2151014506816864, 'learning_rate': 0.003, 'epoch': 2.0}
{'eval_loss': 0.13171450793743134, 'eval_runtime': 0.7505, 'eval_samples_per_second': 13.325, 'eval_steps_per_second': 13.325, 'epoch': 2.0}

{'loss': 0.0388, 'grad_norm': 0.278194785118103, 'learning_rate': 0.002833333333333333, 'epoch': 2.17}
{'loss': 0.0647, 'grad_norm': 0.20627647638320923, 'learning_rate': 0.0026666666666666666, 'epoch': 2.33}
{'loss': 0.0431, 'grad_norm': 0.17176122963428497, 'learning_rate': 0.0025, 'epoch': 2.5}

 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 86/150 [00:12<00:07,  8.96it/s]
{'loss': 0.0642, 'grad_norm': 0.34488609433174133, 'learning_rate': 0.002166666666666667, 'epoch': 2.83}
{'loss': 0.0884, 'grad_norm': 0.3124988377094269, 'learning_rate': 0.002, 'epoch': 3.0}

 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                      | 93/150 [00:14<00:14,  3.98it/s]
{'loss': 0.0207, 'grad_norm': 0.12223582714796066, 'learning_rate': 0.0018333333333333333, 'epoch': 3.17}
{'loss': 0.0261, 'grad_norm': 0.07207000255584717, 'learning_rate': 0.0016666666666666666, 'epoch': 3.33}

 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 107/150 [00:16<00:05,  8.26it/s]
{'loss': 0.073, 'grad_norm': 0.22920481860637665, 'learning_rate': 0.0013333333333333333, 'epoch': 3.67}
{'loss': 0.0999, 'grad_norm': 0.2592065632343292, 'learning_rate': 0.0011666666666666668, 'epoch': 3.83}
{'loss': 0.0327, 'grad_norm': 0.4701160192489624, 'learning_rate': 0.001, 'epoch': 4.0}

 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                    | 120/150 [00:17<00:02, 10.56it/s]
{'loss': 0.0376, 'grad_norm': 0.17491652071475983, 'learning_rate': 0.0008333333333333333, 'epoch': 4.17}

 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 132/150 [00:20<00:02,  6.76it/s]
{'loss': 0.0126, 'grad_norm': 0.05235614255070686, 'learning_rate': 0.0005, 'epoch': 4.5}
{'loss': 0.0867, 'grad_norm': 0.056501150131225586, 'learning_rate': 0.0003333333333333333, 'epoch': 4.67}

 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 149/150 [00:22<00:00,  7.79it/s]
{'loss': 0.0167, 'grad_norm': 0.04630230739712715, 'learning_rate': 0.0, 'epoch': 5.0}

100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:24<00:00,  6.21it/s]
{'train_runtime': 24.1733, 'train_samples_per_second': 6.205, 'train_steps_per_second': 6.205, 'train_loss': 0.1151671202480793, 'epoch': 5.0}