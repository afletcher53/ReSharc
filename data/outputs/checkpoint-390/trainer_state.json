{
  "best_metric": 0.26747626066207886,
  "best_model_checkpoint": "./data/outputs/checkpoint-390",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 390,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02564102564102564,
      "grad_norm": 0.3746504783630371,
      "learning_rate": 0.0049743589743589745,
      "loss": 0.6266,
      "step": 5
    },
    {
      "epoch": 0.05128205128205128,
      "grad_norm": 1.416567325592041,
      "learning_rate": 0.004948717948717949,
      "loss": 0.4624,
      "step": 10
    },
    {
      "epoch": 0.07692307692307693,
      "grad_norm": 0.4465400278568268,
      "learning_rate": 0.004923076923076923,
      "loss": 0.5689,
      "step": 15
    },
    {
      "epoch": 0.10256410256410256,
      "grad_norm": 1.5187485218048096,
      "learning_rate": 0.004897435897435898,
      "loss": 0.4456,
      "step": 20
    },
    {
      "epoch": 0.1282051282051282,
      "grad_norm": 1.1969140768051147,
      "learning_rate": 0.004871794871794872,
      "loss": 0.3142,
      "step": 25
    },
    {
      "epoch": 0.15384615384615385,
      "grad_norm": 0.8241394758224487,
      "learning_rate": 0.004846153846153846,
      "loss": 0.5339,
      "step": 30
    },
    {
      "epoch": 0.1794871794871795,
      "grad_norm": 0.6593533754348755,
      "learning_rate": 0.004820512820512821,
      "loss": 0.2213,
      "step": 35
    },
    {
      "epoch": 0.20512820512820512,
      "grad_norm": 0.30296623706817627,
      "learning_rate": 0.004794871794871795,
      "loss": 0.3832,
      "step": 40
    },
    {
      "epoch": 0.23076923076923078,
      "grad_norm": 1.384635329246521,
      "learning_rate": 0.0047692307692307695,
      "loss": 0.4892,
      "step": 45
    },
    {
      "epoch": 0.2564102564102564,
      "grad_norm": NaN,
      "learning_rate": 0.0047538461538461545,
      "loss": 0.8312,
      "step": 50
    },
    {
      "epoch": 0.28205128205128205,
      "grad_norm": 1.5331690311431885,
      "learning_rate": 0.004738461538461539,
      "loss": 0.9973,
      "step": 55
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 2.253283739089966,
      "learning_rate": 0.004712820512820513,
      "loss": 0.3293,
      "step": 60
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.7175338864326477,
      "learning_rate": 0.004687179487179487,
      "loss": 0.4343,
      "step": 65
    },
    {
      "epoch": 0.358974358974359,
      "grad_norm": 0.9708196520805359,
      "learning_rate": 0.004661538461538462,
      "loss": 0.7062,
      "step": 70
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 1.018166184425354,
      "learning_rate": 0.004635897435897436,
      "loss": 0.4032,
      "step": 75
    },
    {
      "epoch": 0.41025641025641024,
      "grad_norm": 1.4357560873031616,
      "learning_rate": 0.0046102564102564105,
      "loss": 0.4391,
      "step": 80
    },
    {
      "epoch": 0.4358974358974359,
      "grad_norm": 0.771258533000946,
      "learning_rate": 0.004584615384615385,
      "loss": 0.2994,
      "step": 85
    },
    {
      "epoch": 0.46153846153846156,
      "grad_norm": 0.6537236571311951,
      "learning_rate": 0.004558974358974359,
      "loss": 0.4906,
      "step": 90
    },
    {
      "epoch": 0.48717948717948717,
      "grad_norm": 0.23271457850933075,
      "learning_rate": 0.004533333333333333,
      "loss": 0.1684,
      "step": 95
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 0.366607666015625,
      "learning_rate": 0.004507692307692308,
      "loss": 0.5562,
      "step": 100
    },
    {
      "epoch": 0.5384615384615384,
      "grad_norm": 0.4409780204296112,
      "learning_rate": 0.004482051282051282,
      "loss": 0.361,
      "step": 105
    },
    {
      "epoch": 0.5641025641025641,
      "grad_norm": 0.6698353886604309,
      "learning_rate": 0.004456410256410257,
      "loss": 0.1688,
      "step": 110
    },
    {
      "epoch": 0.5897435897435898,
      "grad_norm": 3.4770989418029785,
      "learning_rate": 0.004430769230769231,
      "loss": 0.6601,
      "step": 115
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 1.2290056943893433,
      "learning_rate": 0.0044051282051282056,
      "loss": 0.4822,
      "step": 120
    },
    {
      "epoch": 0.6410256410256411,
      "grad_norm": 0.2543763518333435,
      "learning_rate": 0.004379487179487179,
      "loss": 0.3409,
      "step": 125
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 1.5806244611740112,
      "learning_rate": 0.0043538461538461535,
      "loss": 0.2827,
      "step": 130
    },
    {
      "epoch": 0.6923076923076923,
      "grad_norm": 0.5473930835723877,
      "learning_rate": 0.004328205128205128,
      "loss": 0.5744,
      "step": 135
    },
    {
      "epoch": 0.717948717948718,
      "grad_norm": 2.7770161628723145,
      "learning_rate": 0.004302564102564103,
      "loss": 0.3894,
      "step": 140
    },
    {
      "epoch": 0.7435897435897436,
      "grad_norm": 0.7162584066390991,
      "learning_rate": 0.0042769230769230775,
      "loss": 0.5762,
      "step": 145
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 1.3476965427398682,
      "learning_rate": 0.004251282051282052,
      "loss": 0.6291,
      "step": 150
    },
    {
      "epoch": 0.7948717948717948,
      "grad_norm": 0.6831963062286377,
      "learning_rate": 0.004225641025641025,
      "loss": 0.1581,
      "step": 155
    },
    {
      "epoch": 0.8205128205128205,
      "grad_norm": 0.4423077702522278,
      "learning_rate": 0.0042,
      "loss": 0.2503,
      "step": 160
    },
    {
      "epoch": 0.8461538461538461,
      "grad_norm": 0.4234243631362915,
      "learning_rate": 0.004174358974358974,
      "loss": 0.6508,
      "step": 165
    },
    {
      "epoch": 0.8717948717948718,
      "grad_norm": 0.41049879789352417,
      "learning_rate": 0.004153846153846154,
      "loss": 0.2031,
      "step": 170
    },
    {
      "epoch": 0.8974358974358975,
      "grad_norm": 2.4943137168884277,
      "learning_rate": 0.004128205128205128,
      "loss": 0.3206,
      "step": 175
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 1.0996671915054321,
      "learning_rate": 0.0041025641025641026,
      "loss": 0.7345,
      "step": 180
    },
    {
      "epoch": 0.9487179487179487,
      "grad_norm": 1.065631628036499,
      "learning_rate": 0.004076923076923077,
      "loss": 0.385,
      "step": 185
    },
    {
      "epoch": 0.9743589743589743,
      "grad_norm": 0.46617335081100464,
      "learning_rate": 0.004051282051282051,
      "loss": 0.5838,
      "step": 190
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.75684654712677,
      "learning_rate": 0.004025641025641026,
      "loss": 0.652,
      "step": 195
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.2955986559391022,
      "eval_runtime": 0.9576,
      "eval_samples_per_second": 45.95,
      "eval_steps_per_second": 45.95,
      "step": 195
    },
    {
      "epoch": 1.0256410256410255,
      "grad_norm": 0.5663767457008362,
      "learning_rate": 0.004,
      "loss": 0.2213,
      "step": 200
    },
    {
      "epoch": 1.0512820512820513,
      "grad_norm": 1.3986014127731323,
      "learning_rate": 0.0039743589743589745,
      "loss": 0.2498,
      "step": 205
    },
    {
      "epoch": 1.0769230769230769,
      "grad_norm": 0.5597972869873047,
      "learning_rate": 0.003948717948717949,
      "loss": 0.3614,
      "step": 210
    },
    {
      "epoch": 1.1025641025641026,
      "grad_norm": 0.7320801019668579,
      "learning_rate": 0.003923076923076923,
      "loss": 0.256,
      "step": 215
    },
    {
      "epoch": 1.1282051282051282,
      "grad_norm": 1.3783762454986572,
      "learning_rate": 0.0038974358974358976,
      "loss": 0.3613,
      "step": 220
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 0.6245347857475281,
      "learning_rate": 0.003871794871794872,
      "loss": 0.3229,
      "step": 225
    },
    {
      "epoch": 1.1794871794871795,
      "grad_norm": 0.8274028897285461,
      "learning_rate": 0.0038461538461538464,
      "loss": 0.257,
      "step": 230
    },
    {
      "epoch": 1.205128205128205,
      "grad_norm": 0.25290513038635254,
      "learning_rate": 0.0038205128205128203,
      "loss": 0.4007,
      "step": 235
    },
    {
      "epoch": 1.2307692307692308,
      "grad_norm": 0.5485237836837769,
      "learning_rate": 0.0037948717948717947,
      "loss": 0.464,
      "step": 240
    },
    {
      "epoch": 1.2564102564102564,
      "grad_norm": 0.5704793334007263,
      "learning_rate": 0.003769230769230769,
      "loss": 0.3365,
      "step": 245
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 0.32877492904663086,
      "learning_rate": 0.003743589743589744,
      "loss": 0.3916,
      "step": 250
    },
    {
      "epoch": 1.3076923076923077,
      "grad_norm": 0.273531973361969,
      "learning_rate": 0.0037179487179487183,
      "loss": 0.1895,
      "step": 255
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.5087133646011353,
      "learning_rate": 0.0036923076923076927,
      "loss": 0.2927,
      "step": 260
    },
    {
      "epoch": 1.358974358974359,
      "grad_norm": 0.2906315326690674,
      "learning_rate": 0.0036666666666666666,
      "loss": 0.3476,
      "step": 265
    },
    {
      "epoch": 1.3846153846153846,
      "grad_norm": 0.41664284467697144,
      "learning_rate": 0.003641025641025641,
      "loss": 0.3527,
      "step": 270
    },
    {
      "epoch": 1.4102564102564101,
      "grad_norm": 0.1781402826309204,
      "learning_rate": 0.0036153846153846154,
      "loss": 0.2021,
      "step": 275
    },
    {
      "epoch": 1.435897435897436,
      "grad_norm": 0.3172791004180908,
      "learning_rate": 0.0035897435897435897,
      "loss": 0.4582,
      "step": 280
    },
    {
      "epoch": 1.4615384615384617,
      "grad_norm": 0.19524691998958588,
      "learning_rate": 0.003564102564102564,
      "loss": 0.2514,
      "step": 285
    },
    {
      "epoch": 1.4871794871794872,
      "grad_norm": 0.9378566741943359,
      "learning_rate": 0.003538461538461539,
      "loss": 0.3967,
      "step": 290
    },
    {
      "epoch": 1.5128205128205128,
      "grad_norm": 0.42095324397087097,
      "learning_rate": 0.0035128205128205124,
      "loss": 0.3063,
      "step": 295
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.2986108958721161,
      "learning_rate": 0.0034871794871794873,
      "loss": 0.2591,
      "step": 300
    },
    {
      "epoch": 1.564102564102564,
      "grad_norm": 0.2929207682609558,
      "learning_rate": 0.0034615384615384616,
      "loss": 0.1012,
      "step": 305
    },
    {
      "epoch": 1.5897435897435899,
      "grad_norm": 0.592534065246582,
      "learning_rate": 0.003435897435897436,
      "loss": 0.3333,
      "step": 310
    },
    {
      "epoch": 1.6153846153846154,
      "grad_norm": 1.1234285831451416,
      "learning_rate": 0.0034102564102564104,
      "loss": 0.3236,
      "step": 315
    },
    {
      "epoch": 1.641025641025641,
      "grad_norm": 0.24362316727638245,
      "learning_rate": 0.003384615384615385,
      "loss": 0.2837,
      "step": 320
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.7240253686904907,
      "learning_rate": 0.0033589743589743587,
      "loss": 0.227,
      "step": 325
    },
    {
      "epoch": 1.6923076923076923,
      "grad_norm": 0.28621968626976013,
      "learning_rate": 0.003333333333333333,
      "loss": 0.3196,
      "step": 330
    },
    {
      "epoch": 1.717948717948718,
      "grad_norm": 0.7623562812805176,
      "learning_rate": 0.0033076923076923075,
      "loss": 0.4971,
      "step": 335
    },
    {
      "epoch": 1.7435897435897436,
      "grad_norm": 0.2411782443523407,
      "learning_rate": 0.0032820512820512823,
      "loss": 0.2428,
      "step": 340
    },
    {
      "epoch": 1.7692307692307692,
      "grad_norm": 0.5108322501182556,
      "learning_rate": 0.0032564102564102567,
      "loss": 0.6695,
      "step": 345
    },
    {
      "epoch": 1.7948717948717947,
      "grad_norm": 0.5695626735687256,
      "learning_rate": 0.003230769230769231,
      "loss": 0.1496,
      "step": 350
    },
    {
      "epoch": 1.8205128205128205,
      "grad_norm": 0.2129751592874527,
      "learning_rate": 0.0032051282051282055,
      "loss": 0.1569,
      "step": 355
    },
    {
      "epoch": 1.8461538461538463,
      "grad_norm": 0.8402166366577148,
      "learning_rate": 0.0031794871794871794,
      "loss": 0.6013,
      "step": 360
    },
    {
      "epoch": 1.8717948717948718,
      "grad_norm": 0.36945390701293945,
      "learning_rate": 0.0031538461538461538,
      "loss": 0.6215,
      "step": 365
    },
    {
      "epoch": 1.8974358974358974,
      "grad_norm": 0.14191995561122894,
      "learning_rate": 0.003128205128205128,
      "loss": 0.2797,
      "step": 370
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 0.4011377990245819,
      "learning_rate": 0.0031025641025641025,
      "loss": 0.2469,
      "step": 375
    },
    {
      "epoch": 1.9487179487179487,
      "grad_norm": 0.1276296228170395,
      "learning_rate": 0.0030769230769230774,
      "loss": 0.1473,
      "step": 380
    },
    {
      "epoch": 1.9743589743589745,
      "grad_norm": 1.1236311197280884,
      "learning_rate": 0.0030512820512820517,
      "loss": 0.3233,
      "step": 385
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.27718427777290344,
      "learning_rate": 0.0030256410256410257,
      "loss": 0.3266,
      "step": 390
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.26747626066207886,
      "eval_runtime": 0.9476,
      "eval_samples_per_second": 46.433,
      "eval_steps_per_second": 46.433,
      "step": 390
    }
  ],
  "logging_steps": 5,
  "max_steps": 975,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 266184468725760.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
