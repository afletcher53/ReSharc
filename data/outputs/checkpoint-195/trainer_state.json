{
  "best_metric": 0.2955986559391022,
  "best_model_checkpoint": "./data/outputs/checkpoint-195",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 195,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02564102564102564,
      "grad_norm": 0.3746504783630371,
      "learning_rate": 0.0049743589743589745,
      "loss": 0.6266,
      "step": 5
    },
    {
      "epoch": 0.05128205128205128,
      "grad_norm": 1.416567325592041,
      "learning_rate": 0.004948717948717949,
      "loss": 0.4624,
      "step": 10
    },
    {
      "epoch": 0.07692307692307693,
      "grad_norm": 0.4465400278568268,
      "learning_rate": 0.004923076923076923,
      "loss": 0.5689,
      "step": 15
    },
    {
      "epoch": 0.10256410256410256,
      "grad_norm": 1.5187485218048096,
      "learning_rate": 0.004897435897435898,
      "loss": 0.4456,
      "step": 20
    },
    {
      "epoch": 0.1282051282051282,
      "grad_norm": 1.1969140768051147,
      "learning_rate": 0.004871794871794872,
      "loss": 0.3142,
      "step": 25
    },
    {
      "epoch": 0.15384615384615385,
      "grad_norm": 0.8241394758224487,
      "learning_rate": 0.004846153846153846,
      "loss": 0.5339,
      "step": 30
    },
    {
      "epoch": 0.1794871794871795,
      "grad_norm": 0.6593533754348755,
      "learning_rate": 0.004820512820512821,
      "loss": 0.2213,
      "step": 35
    },
    {
      "epoch": 0.20512820512820512,
      "grad_norm": 0.30296623706817627,
      "learning_rate": 0.004794871794871795,
      "loss": 0.3832,
      "step": 40
    },
    {
      "epoch": 0.23076923076923078,
      "grad_norm": 1.384635329246521,
      "learning_rate": 0.0047692307692307695,
      "loss": 0.4892,
      "step": 45
    },
    {
      "epoch": 0.2564102564102564,
      "grad_norm": NaN,
      "learning_rate": 0.0047538461538461545,
      "loss": 0.8312,
      "step": 50
    },
    {
      "epoch": 0.28205128205128205,
      "grad_norm": 1.5331690311431885,
      "learning_rate": 0.004738461538461539,
      "loss": 0.9973,
      "step": 55
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 2.253283739089966,
      "learning_rate": 0.004712820512820513,
      "loss": 0.3293,
      "step": 60
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.7175338864326477,
      "learning_rate": 0.004687179487179487,
      "loss": 0.4343,
      "step": 65
    },
    {
      "epoch": 0.358974358974359,
      "grad_norm": 0.9708196520805359,
      "learning_rate": 0.004661538461538462,
      "loss": 0.7062,
      "step": 70
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 1.018166184425354,
      "learning_rate": 0.004635897435897436,
      "loss": 0.4032,
      "step": 75
    },
    {
      "epoch": 0.41025641025641024,
      "grad_norm": 1.4357560873031616,
      "learning_rate": 0.0046102564102564105,
      "loss": 0.4391,
      "step": 80
    },
    {
      "epoch": 0.4358974358974359,
      "grad_norm": 0.771258533000946,
      "learning_rate": 0.004584615384615385,
      "loss": 0.2994,
      "step": 85
    },
    {
      "epoch": 0.46153846153846156,
      "grad_norm": 0.6537236571311951,
      "learning_rate": 0.004558974358974359,
      "loss": 0.4906,
      "step": 90
    },
    {
      "epoch": 0.48717948717948717,
      "grad_norm": 0.23271457850933075,
      "learning_rate": 0.004533333333333333,
      "loss": 0.1684,
      "step": 95
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 0.366607666015625,
      "learning_rate": 0.004507692307692308,
      "loss": 0.5562,
      "step": 100
    },
    {
      "epoch": 0.5384615384615384,
      "grad_norm": 0.4409780204296112,
      "learning_rate": 0.004482051282051282,
      "loss": 0.361,
      "step": 105
    },
    {
      "epoch": 0.5641025641025641,
      "grad_norm": 0.6698353886604309,
      "learning_rate": 0.004456410256410257,
      "loss": 0.1688,
      "step": 110
    },
    {
      "epoch": 0.5897435897435898,
      "grad_norm": 3.4770989418029785,
      "learning_rate": 0.004430769230769231,
      "loss": 0.6601,
      "step": 115
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 1.2290056943893433,
      "learning_rate": 0.0044051282051282056,
      "loss": 0.4822,
      "step": 120
    },
    {
      "epoch": 0.6410256410256411,
      "grad_norm": 0.2543763518333435,
      "learning_rate": 0.004379487179487179,
      "loss": 0.3409,
      "step": 125
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 1.5806244611740112,
      "learning_rate": 0.0043538461538461535,
      "loss": 0.2827,
      "step": 130
    },
    {
      "epoch": 0.6923076923076923,
      "grad_norm": 0.5473930835723877,
      "learning_rate": 0.004328205128205128,
      "loss": 0.5744,
      "step": 135
    },
    {
      "epoch": 0.717948717948718,
      "grad_norm": 2.7770161628723145,
      "learning_rate": 0.004302564102564103,
      "loss": 0.3894,
      "step": 140
    },
    {
      "epoch": 0.7435897435897436,
      "grad_norm": 0.7162584066390991,
      "learning_rate": 0.0042769230769230775,
      "loss": 0.5762,
      "step": 145
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 1.3476965427398682,
      "learning_rate": 0.004251282051282052,
      "loss": 0.6291,
      "step": 150
    },
    {
      "epoch": 0.7948717948717948,
      "grad_norm": 0.6831963062286377,
      "learning_rate": 0.004225641025641025,
      "loss": 0.1581,
      "step": 155
    },
    {
      "epoch": 0.8205128205128205,
      "grad_norm": 0.4423077702522278,
      "learning_rate": 0.0042,
      "loss": 0.2503,
      "step": 160
    },
    {
      "epoch": 0.8461538461538461,
      "grad_norm": 0.4234243631362915,
      "learning_rate": 0.004174358974358974,
      "loss": 0.6508,
      "step": 165
    },
    {
      "epoch": 0.8717948717948718,
      "grad_norm": 0.41049879789352417,
      "learning_rate": 0.004153846153846154,
      "loss": 0.2031,
      "step": 170
    },
    {
      "epoch": 0.8974358974358975,
      "grad_norm": 2.4943137168884277,
      "learning_rate": 0.004128205128205128,
      "loss": 0.3206,
      "step": 175
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 1.0996671915054321,
      "learning_rate": 0.0041025641025641026,
      "loss": 0.7345,
      "step": 180
    },
    {
      "epoch": 0.9487179487179487,
      "grad_norm": 1.065631628036499,
      "learning_rate": 0.004076923076923077,
      "loss": 0.385,
      "step": 185
    },
    {
      "epoch": 0.9743589743589743,
      "grad_norm": 0.46617335081100464,
      "learning_rate": 0.004051282051282051,
      "loss": 0.5838,
      "step": 190
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.75684654712677,
      "learning_rate": 0.004025641025641026,
      "loss": 0.652,
      "step": 195
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.2955986559391022,
      "eval_runtime": 0.9576,
      "eval_samples_per_second": 45.95,
      "eval_steps_per_second": 45.95,
      "step": 195
    }
  ],
  "logging_steps": 5,
  "max_steps": 975,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 133092234362880.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
