{
  "best_metric": 0.2269279509782791,
  "best_model_checkpoint": "./data/outputs/checkpoint-30",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 120,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16666666666666666,
      "grad_norm": 0.6719275116920471,
      "learning_rate": 0.004833333333333334,
      "loss": 1.2011,
      "step": 5
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 0.5111392140388489,
      "learning_rate": 0.004666666666666667,
      "loss": 0.3616,
      "step": 10
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.22712242603302002,
      "learning_rate": 0.0045000000000000005,
      "loss": 0.1671,
      "step": 15
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.7334325909614563,
      "learning_rate": 0.004333333333333334,
      "loss": 0.1566,
      "step": 20
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.26802486181259155,
      "learning_rate": 0.004166666666666667,
      "loss": 0.2112,
      "step": 25
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.39890429377555847,
      "learning_rate": 0.004,
      "loss": 0.1375,
      "step": 30
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.2269279509782791,
      "eval_runtime": 0.3814,
      "eval_samples_per_second": 26.221,
      "eval_steps_per_second": 26.221,
      "step": 30
    },
    {
      "epoch": 1.1666666666666667,
      "grad_norm": 0.39432385563850403,
      "learning_rate": 0.0038333333333333336,
      "loss": 0.0841,
      "step": 35
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.36375221610069275,
      "learning_rate": 0.0036666666666666666,
      "loss": 0.1181,
      "step": 40
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.23683921992778778,
      "learning_rate": 0.0034999999999999996,
      "loss": 0.1333,
      "step": 45
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.27205830812454224,
      "learning_rate": 0.003333333333333333,
      "loss": 0.0798,
      "step": 50
    },
    {
      "epoch": 1.8333333333333335,
      "grad_norm": 0.7172653079032898,
      "learning_rate": 0.0031666666666666666,
      "loss": 0.1076,
      "step": 55
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.19956044852733612,
      "learning_rate": 0.003,
      "loss": 0.1726,
      "step": 60
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.2279348373413086,
      "eval_runtime": 0.386,
      "eval_samples_per_second": 25.908,
      "eval_steps_per_second": 25.908,
      "step": 60
    },
    {
      "epoch": 2.1666666666666665,
      "grad_norm": 0.18318146467208862,
      "learning_rate": 0.002833333333333333,
      "loss": 0.1367,
      "step": 65
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 0.27680325508117676,
      "learning_rate": 0.0026666666666666666,
      "loss": 0.0672,
      "step": 70
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.2900853455066681,
      "learning_rate": 0.0025,
      "loss": 0.0541,
      "step": 75
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.22288070619106293,
      "learning_rate": 0.0023333333333333335,
      "loss": 0.0881,
      "step": 80
    },
    {
      "epoch": 2.8333333333333335,
      "grad_norm": 0.30031946301460266,
      "learning_rate": 0.002166666666666667,
      "loss": 0.1146,
      "step": 85
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.12056195735931396,
      "learning_rate": 0.002,
      "loss": 0.0643,
      "step": 90
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.2408474236726761,
      "eval_runtime": 0.3866,
      "eval_samples_per_second": 25.867,
      "eval_steps_per_second": 25.867,
      "step": 90
    },
    {
      "epoch": 3.1666666666666665,
      "grad_norm": 0.10591335594654083,
      "learning_rate": 0.0018333333333333333,
      "loss": 0.0564,
      "step": 95
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.17945678532123566,
      "learning_rate": 0.0016666666666666666,
      "loss": 0.0483,
      "step": 100
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.13295717537403107,
      "learning_rate": 0.0015,
      "loss": 0.0325,
      "step": 105
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 0.10871829837560654,
      "learning_rate": 0.0013333333333333333,
      "loss": 0.0851,
      "step": 110
    },
    {
      "epoch": 3.8333333333333335,
      "grad_norm": 0.10853201895952225,
      "learning_rate": 0.0011666666666666668,
      "loss": 0.0476,
      "step": 115
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.21276462078094482,
      "learning_rate": 0.001,
      "loss": 0.139,
      "step": 120
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.2445596158504486,
      "eval_runtime": 0.3933,
      "eval_samples_per_second": 25.425,
      "eval_steps_per_second": 25.425,
      "step": 120
    }
  ],
  "logging_steps": 5,
  "max_steps": 150,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 297857990707200.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
