# config/config.yaml

# Choose the API provider: "google" or "openrouter"
api_provider: "openrouter"  # <--- CHANGE THIS TO "openrouter" TO USE OPENROUTER

# --- Generic Settings ---
arc_data_dir: "data/arc/"
arc_outputs_dir: "data/outputs/"

training_challenges_file: "arc-agi_training_challenges.json"
training_solutions_file: "arc-agi_training_solutions.json"

evaluation_challenges_file: "arc-agi_evaluation_challenges.json"
evaluation_solutions_file: "arc-agi_evaluation_solutions.json"

raw_generations_output_file: "data/generated_sft/raw_generations.jsonl"
filtered_sft_output_file: "data/filtered_sft/sft_dataset.jsonl"
max_tasks_to_process: 200 # Max tasks for either provider

# Base prompt template for the ARC task
BASE_PROMPT_TEMPLATE: |
  You are an expert in solving Abstraction and Reasoning Corpus (ARC) problems. Analyze the provided input/output examples and determine the transformation rule. Apply this rule to the final test input grid.

  **Task Description:**
  The user will provide several pairs of example input grids and their corresponding output grids. They represent a hidden transformation rule. Finally, a single test input grid is provided. Your goal is to deduce the rule from the examples and apply it to the test input grid to produce the correct test output grid.

  **Output Format:**
  Provide your step-by-step reasoning within `<thinking>` tags. Explain how you identified the pattern and how you are applying it to the test input.
  Provide the final predicted output grid for the test input within `<answer>` tags. The grid should be formatted as a list of lists, with integers representing colors. Example: [[1, 0], [0, 1]]

  Ensure that you check the consistency of your answer.

  ---
  **Current Task:**

  {task_prompt_section}

  ---
  Now, please solve the current task using the specified format. Remember to output the reasoning in <thinking> tags and the final grid as a list of lists in <answer> tags.

# --- Google Generative AI Settings ---
google_settings:
  # Environment variable holding the Google API Key
  api_key_env_var: "GOOGLE_API_KEY"
  # List of Google models to use if api_provider is "google"
  teacher_models:
    - "openai/o3-mini-high"
    # - "gemini-1.0-pro"
  # Optional Generation Configuration
  # generation_config:
  #   temperature: 0.7
  #   max_output_tokens: 2048
  # Optional Safety Settings
  # safety_settings:
  #   HARM_CATEGORY_HARASSMENT: "BLOCK_MEDIUM_AND_ABOVE"
  #   # ... other categories

# --- OpenRouter Settings ---
openrouter_settings:
  # Environment variable holding the OpenRouter API Key
  # api_key_env_var: "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"
  # List of OpenRouter models to use if api_provider is "openrouter"
  # Find models at: https://openrouter.ai/models
  teacher_models:
    # - "google/gemini-flash-1.5" # Example OpenRouter identifier
    - "google/gemini-2.5-pro-preview-03-25"
    # - "mistralai/mistral-7b-instruct"
  # Optional: Recommended headers for OpenRouter
  # See: https://openrouter.ai/docs#headers
  site_url: "http://localhost" # Or your actual site/app URL
  app_name: "arc-grpo-trainer" # Your project's name
  # Optional: Generation parameters (names might differ slightly from Google)
  generation_config:
     max_tokens: 100000 # Corresponds to max_output_tokens for Google
     temperature: 0.3
     # top_p: 1.0
     # frequency_penalty: 0.0
     # presence_penalty: 0.0

baseline_models:
  default_model: "Qwen/Qwen2.5-Coder-0.5B-Instruct" # Baseline model prior to SFT/DPO/GRPO
  max_tokens: 4000 # Max tokens for the baseline model
  limit: 10